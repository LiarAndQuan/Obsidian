
## 表结构梳理

1. user表 : 存储用户信息 , 使用username进行分片
2. group表 : 存储用户短链接分组信息 , 使用username进行分片 , (gid , username)是唯一索引 , 因为每个用户的gid是不一样的
3. link表 : 存储了短链接和原始链接 , 使用gid分片 , (full_short_url , del_time) 是唯一索引 , 因为在删除短链接的时候加的是del_time , 如果我们用的是(url,delflag) , 那么我们删除第一条 , 再添加一条相同的 , 没问题 , 第二次删除就有问题了
4. link_goto表 : 记录的是full_short_url对应的gid , 用于跳转时查询原始链接 , 因为跳转时只拿得到full_short_url , 分片键是(full_short_url)
5. link_access_logs : 记录的是每次访问短链接的访问信息 , 访问一次就是一条记录 , gid分片
6. link_access_stats : 记录的是短链接在某个date , 某个hour内的pv , uv , uip , 唯一索引就是(full_short_url , gid , date , hour) , 我们可以根据这个记录每一天不同小时的记录数 , 进行统计
7. link_browser_stats : 记录短链接某个date , 某个browser访问的总数 , 唯一索引是(full_short_url , gid , date , browser)
8. link_device_stats , network , os , 同上
9. link_locale_stats : 记录某个date , 某个省 , 某个市短链接访问次数 , 唯一索引是(full_short_url , gid , date , province , adcode)
10. link_stats_today : 记录短链接今日访问的pv,uv,uip , 唯一索引是(full_short_url , gid , date)

## 分表规则

user表 : username 
group表 : username
link表 : gid
link_got表 : full_short_url
link_stats_today表 : gid

## 用户名布隆过滤器

```java
@Configuration(value="rBloomFilterConfigurationByAdmin")  
public class RBloomFilterConfiguration {  
  
    /**  
     * 防止用户注册查询数据库的布隆过滤器  
     */  
    @Bean  
    public RBloomFilter<String> userRegisterCachePenetrationBloomFilter(RedissonClient redissonClient) {  
        RBloomFilter<String> cachePenetrationBloomFilter = redissonClient.getBloomFilter("userRegisterCachePenetrationBloomFilter");  
        //设置布隆过滤器的预期容量和失误率,用于初始化  
        cachePenetrationBloomFilter.tryInit(1000, 0.01);  
        return cachePenetrationBloomFilter;  
    }  
}
```

## 用户注册接口

1. 查询用户名是否存在 , 如果存在的话那么就抛出用户名已存在异常
2. 获取分布式锁 , 因为如果大量请求携带同一个未注册的用户名过来 , 那么需要使用分布式锁防止系统崩溃 , 锁标识为 : prefix + username
3. lock.tryLock , 如果没有获取到锁 , 那么就直接退出 , 如果拿到了锁 , 那么就可以执行插入操作
4. 做DuplicatieKeyException异常的处理
5. 在布隆过滤器中加入这个username
6. 给用户添加上一个默认的分组

```java
@Override  
public void register(UserRegisterReqDto requestParam) {  
    if (hasUsername(requestParam.getUsername())) {  
        throw new ClientException(UserErrorCodeEnums.USER_EXIST);  
    }  
    //如果大量请求携带着同一个未注册的用户名过来,那么需要使用分布式锁防止系统崩溃,使用用户名作为锁  
    RLock lock = redissonClient.getLock(LOCK_USER_REGISTER_KEY + requestParam.getUsername());  
    try {  
        //如果拿到了锁,就插入  
        if (lock.tryLock()) {  
            try {  
                int inserted = baseMapper.insert(BeanUtil.toBean(requestParam, UserDo.class));  
                if (inserted < 1) {  
                    throw new ClientException(USER_REGISTER_ERROR);  
                }  
            } catch (DuplicateKeyException e) {  
                throw new ClientException(USER_EXIST);  
            }  
            userRegisterCachePenetrationBloomFilter.add(requestParam.getUsername());  
            groupService.saveGroup(requestParam.getUsername(), "默认分组");  
            return;  
        }  
    } finally {  
        lock.unlock();  
    }  
}
```

## 用户登录接口

1. 在数据库中查询是否有这个用户 , 校验用户名和密码
2. 通过prefix+username查询到在redis里面的token和userinfo信息对 , 是hash结构的
3. 如果非空 , 那么说明已经登录了 , 刷新一下登录时间 , 返回token
4. 如果为空 , 那么需要将{prefix+username : { token , userinfo }}存入redis里面 , 使用uuid生成token , 然后设置过期时间

```java
@Override  
public UserLoginResDto login(UserLoginReqDto requestParam) {  
    LambdaQueryWrapper<UserDo> wrapper = Wrappers.lambdaQuery(UserDo.class)  
            .eq(UserDo::getUsername, requestParam.getUsername())  
            .eq(UserDo::getPassword, requestParam.getPassword())  
            .eq(UserDo::getDelFlag, 0);  
    UserDo userDo = baseMapper.selectOne(wrapper);  
    if (userDo == null) {  
        throw new ClientException(USER_NULL);  
    }  
    //用户已经登录返回对应的token  
    Map<Object, Object> loginMap = stringRedisTemplate.opsForHash().entries(USER_LOGIN_KEY + requestParam.getUsername());  
    if (CollUtil.isNotEmpty(loginMap)) {  
        //用户已经登录,刷新持续时间  
        stringRedisTemplate.expire(USER_LOGIN_KEY + requestParam.getUsername(), 30L, TimeUnit.MINUTES);  
        String token = loginMap.keySet().stream().findFirst().map(Object::toString).orElseThrow(() -> new ClientException("用户登录错误"));  
        return new UserLoginResDto(token);  
    }  
    /*  
     * 接下来存入redis的结构如下:  
     * Key: login_用户名  
     * Value:     *   Key: token     *   value: Json 字符串(用户信息)  
     * */    //首先生成uuid作为token  
    String uuid = UUID.randomUUID().toString();  
    stringRedisTemplate.opsForHash().put(USER_LOGIN_KEY + requestParam.getUsername(), uuid, JSON.toJSONString(userDo));  
    stringRedisTemplate.expire(USER_LOGIN_KEY + requestParam.getUsername(), 30, TimeUnit.DAYS);  
    return new UserLoginResDto(uuid);  
}
```

## 新增分组

1. 获取分布式锁 , 锁名 : prefix + username
2. 生成一个数据库中没有的gid , 就是在数字和字母中随机挑选六个 , 每一位都随机一个
3. 插入

## 创建短链接

1. 验证网站的白名单 , 略
2. 生成一个短链接 , 是使用原始链接拼接一个uuid , 然后将这个字符串使用hutool里面的MurmurHash生成一个hash值 , 得到一个32位的整数 , 然后将这个32位整数转换为62进制 , 5的62次方是10^43 , >10^32 , 所以短链接最多是有5位 , 得到短链接之后 , 需要判断短链接是否存在 , 如果存在的话 , 那么需要重新生成 . 然后加入到布隆过滤器中 
3. 将生成的短链接插入到数据库中 , 然后还要新增一条linkGoto记录 , 记录了full_short_url和gid的关系 , 这里是为了后面短链接的跳转 , 根据full_short_url先查询到gid才能查询到这条记录
4. 缓存预热 , 添加进redis

## 修改短链接

1. 查询修改的短链接是否存在
2. 如果传入的gid是相同的 , 那么是相同的 , 那么直接就可以更改
3. **如果gid是不同的 , 那么就需要先删除在修改 , 如果访问的时候正好修改了短链接的信息 , 那么监控日志之类的可能会记录出错 , 因为如果修改了gid , 那么就会导致前一半的表统计的是原来的gid , 后一半的表统计的就是修改之后的gid了 , 所以我们需要对修改进行加锁 , 如果加的是分布式锁 , 那么会影响性能 , 因为这是读多写少的场景 , 所以我们使用读写锁**
4. **先获取写锁 , trylock , 如果获取不到那么就提示短链接正在被访问 , 请稍后再试**
5. 首先删除原来的数据 , 这里的删除是将delTime改成当前的时间戳 , 然后添加上新的Link数据
6. 根据原始gid和full_short_url删除各个监控表里面的数据 , 然后改成新的gid
7. 如果有效期被修改了 , 那么就直接删除缓存
8. 如果是将过期的短链接 , 并且刚刚被访问了 , 然后就会在redis里面缓存一个null值 , 这时候我们将短链接更新成有效的 , 然后我们就必须要删除一下这个null的key

## 短链接的跳转

1. 首先判断端口号是不是80 , 因为如果是在本地测试的 , 那么我们就需要输入本地的中台服务的端口 , 但是如果是部署在服务器的 , 那么就默认是80端口访问的 , 我们需要拼接出完整的full_short_url(域名+端口(8003或者空)+shorturl)
2. 然后去redis里面查询是否有对应的缓存{full_short_url : origin_url} , 如果有的话 , 那么直接302重定向即可
3. 如果缓存中不存在 , 那么先查询布隆过滤器是否存在 , 如果不存在就直接返回404 , 因为布隆过滤器查询不存在那么就一定不存在
4. 查询这个url是否在redis里面存了null标记 , 因为布隆过滤器可能会误判 , 将不存在的误判成了存在 , 这就导致我们后面查询数据库发现为空 , 这时候为了防止重复查询这个误判的值 , 也就是缓存穿透 , 我们缓存一个null值在redis , 如果发现这个url被标记了 , 那么返回404
5. 走到这里了, 说明有两种可能 , 一种是数据库中有缓存中没有 , 需要去加载 , 一种是数据库中也没有 , 但是由于是第一次查询 , 需要我们缓存null值
6. 先进行加锁 , 锁名 : prefix+full_short_url , 然后获取锁之后 , 再次判断是否在缓存中 , 因为被阻塞的期间可能会有别的请求已经查询到了这条full_short_url并且放入缓存中了 , 这也就是双重判定
7. 走到这里说明我们确实需要自己查询数据库了 , 先根据linkGoto表查询到gid , 因为使用的是gid进行分片的 , 这里在添加短链接的时候会维护linkGoto表 . 如果linkGoto表里面没有记录 , 那么就说明发生了缓存穿透 , 那么缓存一个null值 . 否则的话就根据gid和full_short_url查询到原始链接 , 然后判断是否为null或者过期 , 过期也要缓存null . 然后加入到redis中 , 进行跳转即可
8. 监控短链接

跳转语句 : ((HttpServletResponse) servletResponse).sendRedirect(originUrl);

## 短链接监控

1. 在短链接跳转之后构建出一个LinkStatsRecordDto , 里面包括了此次访问的所有信息 , 比如ip , os , browser , device , network , uv , uvFirstFlag , uipFirstFlag等等
2. 怎么构建的呢 ?  对于uv来讲 , 我们需要通过cookies判断是否是同一个用户访问 , 先获取到所有的cookies , 然后遍历cookies , 如果找到key为'uv'的cookie , 然后判断是不是合法的cookie , 就是往redis的set里面加入cookie , 通过返回值看看是否添加成功 , 如果 = 1的话说明不合法 , 因为说明是第一次访问的 , 否则的话就是合法的(返回值是成功添加元素的数量) . 请求值找不到'uv'这个cookie那么添加就好了 , cookie是使用uuid生成的 , 然后加入redis里面 , 然后给cookie添加路径为/full_short_url , 这样每次访问这个url都会携带cookie
3. 然后那些os , browser , device是通过获取请求头里面的User-Agent获取的
4. ip , network等
#todo
5. 构建完之后连同full_short_url和gid发送到消息队列里面
6. 消息队列接受之后 , 进行幂等判断 , 如果消费过 , 然后再判断是否消费完成 , 如果没有消费完成 , 那么就抛出异常等待重新消费 , 如果消费过并且消费完成那么返回就好了
7. 进行监控的记录 , 监控记录的时候获取读锁 , 这里的读表示修改监控表 , key为prefix + fullshorturl , **如果获取失败 , 说明有人在进行写操作 , 这里的写代表的是正在修改短链接** , 因为如果有人在进行修改短链接我们去记录肯定会出问题 , 如果没有获取到读锁 , 那么就放入延迟消费队列里面去 , 时间到了重新消费即可 . 延迟时间是5分钟 , 然后重新投入消息队列
8. 如果获取到了读锁 , 那么插入记录就好了 , 完成之后修改幂等标记为已消费 , 如果出现了异常, 那么在异常里面删除这个幂等key , 如果正常消费完成 , 那么就设置已完成就好了 , 还需要删除这条消息

## 幂等是怎么做的

幂等的key是 prefix + messageId , 然后存入redis , 存入值为0 , 表示已经开始消费了 , 然后消费完成就会将值修改成1

消费之前会判断是否有这个key(代表有没有被消费过) , 然后判断值是否为1(判断是否正常消费完成) , 如果都满足那么不需要消费了 , 然后如果不满足 , 那么需要重新消费

消费过程中如果出现了异常 , 那么就需要删除这个幂等key

如果成功消费完成 , 那么删除消息 , 设置幂等key状态为1代表已消费完成

如果有消息被投入到延迟队列里面了 , 那么从延迟队列里面去轮询取出 , 取的时候还是需要判断有没有消费完成的 , 消费成功删除消息 , 未成功删除幂等key , (重新投递到延迟队列)

## 如何做的限流

1. 在redis里面存一个prefix+username , 值就是访问次数
2. 递增访问次数 , 获取递增后的值 , 设置过期时间为窗口的长度 , 1s
3. 返回访问次数 , 判断是否超过了限制的访问次数

```lua
-- 设置用户访问频率限制的参数  
local username = KEYS[1]  
local timeWindow = tonumber(ARGV[1]) -- 时间窗口，单位：秒  
  
-- 构造 Redis 中存储用户访问次数的键名  
local accessKey = "short-link:user-flow-risk-control:" .. username  
  
-- 原子递增访问次数，并获取递增后的值  
local currentAccessCount = redis.call("INCR", accessKey)  
  
-- 设置键的过期时间  
redis.call("EXPIRE", accessKey, timeWindow)  
  
-- 返回当前访问次数  
return currentAccessCount
```

## 用的什么方式生成的短链接

主要就是两个方面，通过 Hash 算法将原始连接转换成一个 Hash 码，这里使用了 Google 出品的 MurmurHash 算法。因为生成的 Hash 码是十进制的，整体较长不利于短链接传播。为此，我们将十进制转换为 62 进制，也就是咱们最终的短链接。

### MurmurHash算法

对于选择哈希函数，有很多人可能会提到使用 MD5、SHA 等加密算法。其实我们并不关心反向解密的难度，更重要的是关注哈希的运算速度和冲突概率。

最终推荐使用由 Google 开发的 MurmurHash 算法。MurmurHash 是一种非加密型哈希函数，适用于一般的哈希检索操作。与其他流行的哈希函数相比，MurmurHash 在处理规律性较强的键时具有更好的随机分布特性。由于它是非加密型的，相比 MD5、SHA 等加密算法，MurmurHash 的性能要高得多（实际上是 MD5 等加密算法的十倍以上）。正是由于这些优点，尽管它于 2008 年问世，但目前已广泛应用于 Redis、MemCache、Cassandra、HBase、Lucene 等许多知名软件中。

我们使用 Hutool 里的工具类，不过他的底层也是使用的 Google 算法

### 进制转换

Base62 编码是将数据转换为只包含数字和字母的一种方法。它使用了 62 个字符，分别是 0-9、a-z、A-Z，可以作为 URL 短链接、文件名等场景的字符串表示，相对于 16 进制或 64 进制等其他编码，Base62 具有更高的可读性和稳定性。

### 为什么会产生冲突

哈希函数将输入的数据映射为一个固定长度的哈希值，而不同的输入可能会映射为相同的哈希值，这被称为哈希冲突。

在短链接生成过程中，原始长链接经过哈希函数进行计算，生成一个哈希值。如果两个不同的原始长链接经过哈希计算后得到相同的哈希值，那么它们将生成相同的短链接。

这种情况通常是由于哈希函数的输出空间有限，而输入空间却是无限的。因此，无论哈希函数的设计有多好，仍然存在一定的概率会出现冲突。

### 为什么使用原始链接和UUID生成短链接

生成的短链接是需要保障在当前域名下唯一的，那这个唯一又如何体现呢？每次查询数据库中已有短链接数据来判断是否唯一么？性能有点低，我们使用了布隆过滤器来进行判断。

当我们发现冲突后，将原始长链接与一个随机生成的 UUID 字符串拼接，通过拼接后的内容继续查询布隆过滤器，直到不存在为止。

### 为什么不直接使用uuid

其实是可以的。但是，有一个差强人意的理由，那就是生成 UUID 需要耗费时间，哪怕是极小的时间。

我们**开始使用原始url来生成 , 冲突了再拼接uuid**

### 为什么不只使用原始链接

产生冲突啊

### 一直冲突怎么办

如果超过指定次数，就抛出异常。

## 如何跳转

1. 首先判断端口号是不是80 , 因为如果是在本地测试的 , 那么我们就需要输入本地的中台服务的端口 , 但是如果是部署在服务器的 , 那么就默认是80端口访问的 , 我们需要拼接出完整的full_short_url(域名+端口(8003或者空)+shorturl)
2. 然后去redis里面查询是否有对应的缓存{full_short_url : origin_url} , 如果有的话 , 那么直接302重定向即可
3. 如果缓存中不存在 , 那么先查询布隆过滤器是否存在 , 如果不存在就直接返回404 , 因为布隆过滤器查询不存在那么就一定不存在
4. 查询这个url是否在redis里面存了null标记 , 因为布隆过滤器可能会误判 , 将不存在的误判成了存在 , 这就导致我们后面查询数据库发现为空 , 这时候为了防止重复查询这个误判的值 , 也就是缓存穿透 , 我们缓存一个null值在redis , 如果发现这个url被标记了 , 那么返回404
5. 走到这里了, 说明有两种可能 , 一种是数据库中有缓存中没有 , 需要去加载 , 一种是数据库中也没有 , 但是由于是第一次查询 , 需要我们缓存null值
6. 先进行加锁 , 锁名 : prefix+full_short_url , 然后获取锁之后 , 再次判断是否在缓存中 , 因为被阻塞的期间可能会有别的请求已经查询到了这条full_short_url并且放入缓存中了 , 这也就是双重判定
7. 走到这里说明我们确实需要自己查询数据库了 , 先根据linkGoto表查询到gid , 因为使用的是gid进行分片的 , 这里在添加短链接的时候会维护linkGoto表 . 如果linkGoto表里面没有记录 , 那么就说明发生了缓存穿透 , 那么缓存一个null值 . 否则的话就根据gid和full_short_url查询到原始链接 , 然后判断是否为null或者过期 , 过期也要缓存null . 然后加入到redis中 , 进行跳转即可

### 为什么使用302重定向而不是301

两者区别是：

- 301：表示永久性转移。会导致搜索引擎将旧的URL替换为新的 URL，并且浏览器会缓存新的 URL。对于后续的请求，浏览器会直接使用新的 URL 进行访问，而不会再发送请求到旧的 URL。
- 302：表示临时性转移。不会导致搜索引擎更新索引，它只是暂时重定向到新的 URL。浏览器会缓存新的 URL，但对于后续的请求，浏览器会继续发送请求到原始的 URL，而不是直接使用新的 URL。

简单来说，通过 301 跳转，只会在访问一次后端请求，然后就被缓存到浏览器，后续就直接从浏览器拿，不需要再访问短链接服务了。

302 跳转，每次都需要去短链接服务获取最新的链接，再进行重定向，浏览器不缓存相关信息。

两者优缺点：

- 301：优点对短链接后端服务压力比较小。缺点是后续短链接变更了原始链接，无法感知；以及无法记录详细的统计信息。
- 302：上边的缺点就是优点。缺点是每次访问后端服务器，可能压力会大一些，但是相对于获取到用户的行为，这种小缺点都是能接受的。

## 判断短链接存在为什么不使用Set

### 占用空间大

当使用布隆过滤器时，它使用了一个位数组来表示元素的存在性。这个位数组的长度通常会根据预期的元素数量进行设置。相比之下，Set 结构需要存储元素的实际值。

因为 Set 结构需要存储实际的元素值。在内存中，每个元素都需要占用一定的空间。对于大量元素的情况，存储这些元素所需的内存空间会相应增加。

举个例子来说明，假设我们有一个存储 1,000,000 个短链接的数据集。如果使用 Set 结构来存储这些短链接，每个短链接可能需要几十个字节的空间。这意味着存储这些元素可能需要数十兆字节的内存。

相比之下，使用布隆过滤器可以显著减少内存消耗，从而节省大量内存空间。

如果存储 1亿元素，误判率设置为 0.001 也就是千分之一，仅需要占用 171M 左右的内存。

需要注意的是，布隆过滤器的位数组长度和哈希函数的数量会影响到误判率和内存消耗之间的权衡。较小的位数组和较少的哈希函数可能会降低内存消耗，但也会增加误判率。因此，在使用布隆过滤器时，需要根据实际需求和对误判率的容忍程度进行适当的配置。

### 大key

那么极有可能会发生一个 Set 存储数百万甚至上千万的元素，这就涉及到大 Key 问题。

大 Key 可能会导致以下问题：

- **内存碎片化**：大 Key 占用的内存块较大，可能导致内存碎片化，从而影响 Redis 的内存使用效率。
- **网络传输延迟**：传输大 Key 的数据可能会导致较长的网络传输时间，特别是在进行备份、迁移或从节点同步等操作时。
- **删除阻塞**：在删除大 Key 的过程中，可能会导致其他操作的响应时间变长。这是因为在删除大 Key 时，需要遍历键中的所有元素，并在内部进行相应的清理操作。在此期间，其他操作会等待删除操作完成。
- **持久化延迟**：如果 Redis 实例使用了持久化机制（如 RDB 快照或 AOF 日志），删除大 Key 可能会导致持久化操作的延迟，因为持久化过程也需要处理大 Key 的数据。

## 如果布隆过滤器挂了 , 里面存的数据丢了怎么办

这个问题本质上是错误的，为什么呢？布隆过滤器存在于 Redis 内存中，所以如果说挂，应该是整个 Redis 挂掉，而不仅仅说是布隆过滤器挂。
基于这个问题，我考虑到了两个场景，这里分别说说。

### Redis宕机 , 数据能恢复吗

如果我们没开启任何持久化机制，那么会丢失全部数据，否则只会丢失部分数据，丢失数据的多少取决于持久化配置。

Redis 提供了两套持久化机制，一个是 RDB，它会根据情况定期的 Fork 出一个子进程，生成当前数据库的全量快照；另一个是 AOF，它通过向 AOF 日志文件追加每一条执行过的指令实现。

而对于 RDB 快照**，假如我们在 RDB 快照生成后宕机，那么会丢失快照生成期间全部增量数据，如果在连快照都没成功生成，那么就会丢掉全部数据**。

而当我们仅开启了 AOF 时，**丢失数据的多少取决于我们设置的刷盘策略**：当设置为每条指令执行后都刷盘 `Always`，我们最多丢失一条指令；当设置为每秒刷一次盘的 `Eversec` 时，最多丢失一秒内的数据；当设置为非主动刷盘的 `No` 时，则可能丢失上次刷盘后到现在的全部数据。

所以，我们为了避免数据过多丢失，一般都会采用 AOF 方式。由于通过 AOF 恢复数据相对比较耗时，因此 Redis 在 4.0 以后允许通过 `aof‐use‐rdb‐preamble` 配置开启混合持久化。

当 AOF 重写时，它将会先生成当前时间的 RDB 快照，然后将其写入新的 AOF 文件，接着再把增量数据追加到这个新 AOF 文件中。如此一来，当 Redis 通过 AOF 文件恢复数据时，将会先加载 RDB，然后再重放后半部分的增量数据。这样就可以大幅度提高数据恢复的速度。

### Redis返回成功 , 但是布隆过滤器持久化指令失败了 , 会生成重复短链接吗

上面有说，使用 AOF 极端情况下会丢失一条数据，那如果说我们像 Redis 布隆过滤器新增一条短链接记录，Redis 返回给我们成功了。但是，恰巧持久化磁盘时 Redis 宕机了。这种情况怎么办？

可能会造成什么问题呢？假设生成了 `isjkd8` 的短链接，本来应该判断布隆过滤器中存在的，结果变成了不存在，那么就会执行数据库的新增流程，可能就会造成一个短链接数据库有着两条记录的问题。

不过还好，我们在数据库创建了唯一索引，会直接抛异常出来，不会造成脏数据。

## todo : 为什么说布隆过滤器性能远胜分布式锁

做了压测

## 并发量有多少

### 并发量指的是什么

![](Attachments/Images/Pasted%20image%2020240324175244.png)

简而言之，如果面试官问并发量，那么一般泛指短链接创建接口。

如果问具体 TPS 或者 QPS 的话，我们可以分别回答短链接创建和短链接跳转访问接口。

### 项目并发量指的是项目还是具体接口

在我看来，很少会存在说项目并发量这个说法，除非项目只对外提供一个接口。为什么这么说？因为我们项目中会存在多种类型的接口，各自差异比较大，所以没办法统一。

假设我们有个订单服务，其中有两个接口：下单和取消支付功能。下单接口单个执行需要 1 秒的时间，而发起取消订单只需要 50 毫秒。假设下单的 TPS 是 200，那取消订单接口的 QPS 就是 4000。那么请问，项目的并发量是多少呢？

一般来说，项目并发量泛指最为核心的一些接口，拿咱们短链接举例，自然就是短链接新增接口。所以，我们回答并发量就说短链接新增就好。

### 短链接新增的TPS有多少呢

在和面试官说时，一定要先明确自己的部署配置，比如：

40 个线程循环 100 次压测，**最终吞吐量大概在 3300 左右**

## 缓存预热怎么做的

在新增的时候就加入缓存中 , 设置了一个月的过期时间

## 介绍一下短链接项目

短链接是指将一个原始的长 URL 通过特定的算法或服务转化为一个更短、易于记忆的 URL。原始的长 URL 可能会非常长，而短链接通常只包含几个字符，然后通过访问短链接跳转到原始链接。

用户可以创建和管理自定义的短链接，同时还可以获得有关短链接的统计数据，如点击次数、地理位置、设备类型等，体验开箱即用的便利服务。

短链接经常出现在咱们日常生活中，大家总是能在某些活动节日里收到各种营销短信，里边就会出现短链接。帮助企业在营销活动中，识别用户行为、点击率等关键信息监控。

主要作用包括但不限于以下几个方面：

- **提升用户体验**：用户更容易记忆和分享短链接，增强了用户的体验。
- **节省空间**：短链接相对于长 URL 更短，可以节省字符空间，特别是在一些限制字符数的场合，如微博、短信等。
- **美化**：短链接通常更美观、简洁，不会包含一大串字符。
- **统计和分析**：可以追踪短链接的访问情况，了解用户的行为和喜好。

## 项目中包含几个模块

短链接项目采用 SaaS 方式开发。"SaaS"代表“软件即服务”（Software as a Service），与传统的软件模型不同，SaaS 不需要用户在本地安装和维护软件，而是通过互联网直接访问在线应用程序。

从业务上来说分为以下几个模块：

- **网关服务**：服务请求分发和鉴权等。
- **用户服务**：用户登录、注册以及个人信息查看等功能。
- **分组服务**：短链接分组的增删改查功能。
- **短链服务**：包含短链接创建、修改以及访问监控等。

通过项目中的亮点和难点分为：

- **海量并发**：可能会面对大量用户同时访问的情况，尤其高峰期，会对系统的性能和响应速度提出很高的要求。
- **海量存储**：可能需要存储大量的用户数据，包括数据库、缓存等，需要足够的存储和高效的存储管理方案。
- **缓存一致性**：修改了短链接后，如何保障数据库的缓存和数据库保持一致性。
- **缓存击穿&穿透**：缓存绕不过的坎，看咱们如何使用布隆过滤器、缓存空值以及分布式锁解决。
- **系统限流**：当服务访问量超过系统承载量时，极端情况服务宕机，用户无法访问等问题，如何解决。

## 短链接如何保证数据一致性

短链接修改功能使用了先更新数据库，再删除缓存的方式保障一致性。

在 `ShortLinkServiceImpl#updateShortLink` 方法种有这一段逻辑，发现数据变更了，先更新数据库，然后再删除缓存。

删除缓存后，如果用户访问短链接，缓存中查询不到，就会去数据库进行查询，最后再放入到缓存中。通过该方式能够有效避免数据库和缓存不一致问题。

而且该方式实现比较简单，不依赖额外中间件，从实时性以及技术实现复杂度来说都比较不错，推荐大家在系统并发较小的情况下使用这种方案。

**有什么问题?**

考虑此时没有缓存 , 一个业务要查然后加缓存 , 另一个要更新再删除缓存

**缓存能不能删除**

能不能延迟双删?

不能 , 在涉及海量并发的场景中，如果程序删除了缓存，可能会导致缓存击穿问题，而更新频繁时则可能引发缓存雪崩。

因此，在考虑缓存一致性模型时，务必充分考虑业务场景是否属于高并发模型。如果是高并发场景，删除缓存可能并不合适，此时应采用最终一致性策略。

那就应该引发出来 Canal 配合 Binlog 的形式解决缓存和数据库最终一致性问题。

## 消息队列为什么使用RocketMQ而不是Kafka

用户访问短链接时，需要记录相关的监控信息并保存到数据库中。

如果这个逻辑放在访问的过程里的话，那么会带来两个耗时：

- 需要从请求头中获取一系列信息，比如地区、IP、访问设备等。
- 保存相关的数据到 MySQL 数据库表。

第一个问题只是会带来吞吐量下降问题，其实还好，不是不能接受。但是第二个问题就比较严重了，如果大量的用户访问短链接，极有可能将 MySQL 的数据库服务打宕机。

为此，我们需要将上述的流程进行削峰操作，通过 RocketMQ 消息中间件分离该逻辑，保障吞吐量提升以及数据库安全。

![](Attachments/Images/Pasted%20image%2020240324181937.png)


1. 功能方面

- Kafka 不支持广播消息。
- Kafka 不支持延时消息。
- Kafka 不支持事务消息。
- Kafka 不支持消息轨迹。
- Kafka 在处理顺序消息时，如果一台 Broker 宕机后，会产生消息乱序。而 RocketMQ 如果消息消费失败，会暂停消费。
- Kafka 不支持基于 Broker 的 Tag 消息过滤（这个我存疑，说不定后面版本会出现），RocketMQ 支持。
- 存疑点：网上说当 Kafka 分区多的时候，性能会下降，RocketMQ 不会。

2. 语言方法

	Kafka 使用 Java 和 Scala，针对一些框架原理查看不便利。

3. 使用场景

- Kafka 侧重于通过流处理引擎实现实时数据流处理，在大数据流处理和实时数据分析方面使用较多。
- RocketMQ 的设计更注重实现高可用和多功能的消息服务，在国内较多公司应用较为广泛。

## 删除短链接之后 , 布隆过滤器怎么删除

不能删除 , 可以加一层set , 将不用的短链接放进去
也没必要删除




